## introduction

_the retrieval problem:_

- = given an information need expressed as a query $q$, the text retrieval task is to return a ranked list of $k$ texts $d_1, d_2, \dots, d_k$ from an arbitrarily large but finite collection of texts $C = d_i$ that maximizes a metric of interest, for example, nDCG, AP, etc.
- information retrieval is about searching information.
- in most contexts, "ranking" and "retrieval" mean the same thing.
- alternative names: the search problem, the information retrieval problem, the text ranking problem, the top-k document retrieval problem.

_definitions:_

- search query: representation of an information need.
- document collection / corpus: collection of documents with unique ids.
- ranking: ranked list of document ids, based on “relevance”, which can be binary or graded on a scale.

_the evaluation problem:_

- “relevance judgments” / “qrels” are optimal query results to benchmark retrieval systems.
- the “metric” is the quality of a single query result.

_ir stages:_

1. training phase: system gets trained with dataset.
2. indexing phase: indexer takes the document collection to build an “index”, which is a data structure that supports fast reads.
3. retrieval / search phase: system returns a ranked list based on query.

## bi-encoders

_data representation:_

- sparse representation vectors:
     - have mostly zero values (that we leave out) with only a few non-zero values.
     - unable to capture semantic relationships.
     - we use inverted indexes.
- dense representation vectors:
     - mostly contain non-zero values.
     - commonly embedding vectors (dense vector represenations generated by learning encoders called “transformers”).
     - dimensions also capture some "latent semantic space".
     - we use hierarchical navigable small-world networks (hnsw) ie. from the faiss library.
- embedding vectors: output of learning encoders called “transformers”.
- representations can be unsupervised/heuristic or supervised/learned.

_components:_

- document encoder: takes a document, returns document representation.
- query encoder: takes a query, returns query representation.
- comparison function: takes 2 representations, returns relevance score / query-document score.
     - ie: n-dimensional float vector as the representation, dot product as the score.
     - ie: k-nearest neighbor search in vector space.

_example: BM25_

- representation: sparse vectors, no semantics, based on heuristic
- document encoder: bm25 encoding is a “bag-of-words” (sparse lexical vectors)
- query encoder: hot-vector.
- comparison function: top-k retrieval from a probabilistic model of how frequent words occur.

## source

- https://github.com/castorini/anserini/blob/master/docs/start-here.md
- https://github.com/castorini/anserini/blob/master/docs/reproducibility.md
- https://github.com/castorini/anserini/blob/master/docs/experiments-msmarco-passage.md
- https://github.com/castorini/pyserini/blob/master/docs/conceptual-framework.md
- https://github.com/castorini/pyserini/blob/master/docs/experiments-nfcorpus.md
- https://github.com/castorini/pyserini/blob/master/docs/conceptual-framework2.md
